\documentclass{article}

\addtolength{\oddsidemargin}{-.875in}
\addtolength{\evensidemargin}{-.875in}
\addtolength{\textwidth}{1.5in}

\addtolength{\topmargin}{-.875in}
\addtolength{\textheight}{1.75in}

\usepackage[utf8]{inputenc}
\usepackage[english]{babel}
\usepackage[dvipsnames]{xcolor}
\usepackage{hyperref}

\begin{document}
\SweaveOpts{concordance=TRUE}

\Large{Extract from:}

\medskip

\large{Bradley Efron and Trevor Hastie}

\large\textit{Computer Age Statistical Inference: Algorithms, Evidence, and Data Science}

\large\textit{Cambridge Unviersity Press, 2016}

\def\UrlFont{\em}
\large\url{https://web.stanford.edu/~hastie/CASI_files/PDF/casi.pdf}

\bigskip

\bigskip

\bigskip

\bigskip

\Large{\fontfamily{qpl}\selectfont   Modern Bayesian practice uses various strategies to construct an appropriate "prior" $g(\mu)$in the absence of prior experience, leaving many statisticians unconvinced by the resulting Bayesian inferences. Our second example illustrates the difficulty.}

\bigskip

\Large{\fontfamily{qpl}\selectfont\textcolor{blue}{Table 3.1} Scores from two tests taken by 22 students, \ttfamily\textcolor{OliveGreen}{mechanics} \fontfamily{qpl}\selectfont{and} \ttfamily\textcolor{OliveGreen}{vectors}.}

\bigskip

\begin{table}[ht]
\begin{center}
\Large
\begin{tabular}{lrrrrrrrrrrr}
       & 1 & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 \\ 
  \hline                                                   
  \ttfamily\textcolor{OliveGreen}{mechanics}     & 7 & 44 & 49 & 59 & 34 & 46 & 0 & 32 & 49 & 52 & 44 \\ 
  \ttfamily\textcolor{OliveGreen}{vectors}       & 51 & 69 & 41 & 70 & 42 & 40 & 40 & 45 & 57 & 64 & 61 \\ 

   \hline
\end{tabular}
\end{center}
\end{table}

\begin{table}[ht]
\begin{center}
\Large
\begin{tabular}{lrrrrrrrrrrr}
       & 12 & 13 & 14 & 15 & 16 & 17 & 18 & 19 & 20 & 21 & 22 \\ 
  \hline                                                   
  \ttfamily\textcolor{OliveGreen}{mechanics}     & 36 & 42 & 5 & 22 & 18 & 41 & 48 & 31 & 42 & 46 & 63 \\ 
  \ttfamily\textcolor{OliveGreen}{vectors}       & 59 & 60 & 30 & 58 & 51 & 63 & 38 & 42 & 69 & 49 & 63 \\ 

   \hline
\end{tabular}
\end{center}
\end{table}

\Large{\fontfamily{qpl}\selectfont Table 3.1 shows the scores on two tests, \ttfamily\textcolor{OliveGreen}{mechanics} and \ttfamily\textcolor{OliveGreen}{vectors}, \fontfamily{qpl}\selectfont achieved by $n = 22$ students. The sample correlation coefficients between the two scores is $\hat{\theta} = 0.498$.}


$$\hat{\theta} = \sum_{i=1}^{22}(m_i - \bar{m})(v_i - \bar{v}) \Biggm/  \left[ \sum_{i=1}^{22}(m_i - \bar{m})^2 \sum_{i=1}^{22}(v_i - \bar{v})^2 \right] ^{1/2}$$

\Large{\fontfamily{qpl}\selectfont with $m$ and $v$ short for \ttfamily\textcolor{OliveGreen}{mechanics} \fontfamily{qpl}\selectfont and \ttfamily\textcolor{OliveGreen}{vectors}, \fontfamily{qpl}\selectfont $\bar{m}$  and $\bar{v}$ their averages.}

\end{document}